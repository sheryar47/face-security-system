{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d167d-0cdf-43b7-b1b9-1069fa6ed752",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e10365-f622-4e37-a74c-34092395ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9094127-e8e1-400f-b260-5b82d3f88012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# Set the directory to save the captured image\n",
    "save_directory = r\"C:\\Users\\Manan Computer\\Desktop\\face capture system\"\n",
    "os.makedirs(save_directory, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 135)  # Calm speech rate\n",
    "engine.setProperty('volume', 0.9)  # Soft tone\n",
    "\n",
    "# Load Face Detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start video capture with high resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)  # Set width to 1920 pixels\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)  # Set height to 1080 pixels\n",
    "\n",
    "# Flag to track face detection\n",
    "face_detected = False\n",
    "\n",
    "def recognize_speech():\n",
    "    \"\"\"Enhanced speech recognition system with noise reduction & retries.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Adjusting for background noise...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1.5)  # Better noise reduction\n",
    "        print(\"Listening for speech...\")\n",
    "        \n",
    "        for _ in range(3):  # Allow up to 3 attempts\n",
    "            try:\n",
    "                audio = recognizer.listen(source, timeout=5)  # Timeout prevents hanging\n",
    "                response = recognizer.recognize_google(audio).lower()\n",
    "                print(\"User said:\", response)\n",
    "                return response\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand, trying again...\")\n",
    "            except sr.RequestError:\n",
    "                print(\"Speech service unavailable, trying again...\")\n",
    "            except sr.WaitTimeoutError:\n",
    "                print(\"No speech detected, trying again...\")\n",
    "\n",
    "        print(\"Failed to recognize speech after 3 attempts.\")\n",
    "        return None  # Return None if no successful recognition\n",
    "\n",
    "def handle_face_detection(frame):\n",
    "    \"\"\"Handles face detection and initiates interaction.\"\"\"\n",
    "    global face_detected, cap\n",
    "    if not face_detected:\n",
    "        face_detected = True\n",
    "        \n",
    "        # Improve image quality\n",
    "        frame = cv2.GaussianBlur(frame, (3, 3), 0)  # Reduce noise\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        \n",
    "        # Apply contrast enhancement\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced_gray = clahe.apply(gray)\n",
    "        frame = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Save the best-quality image\n",
    "        image_path = os.path.join(save_directory, \"detected_face.jpg\")\n",
    "        cv2.imwrite(image_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # High-quality save\n",
    "        print(f\"Photo captured and saved as {image_path}\")\n",
    "        \n",
    "        # Release the camera immediately after detecting a face\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        engine.say(\"Aslam-ul-Allakium, Sheryar! It's always nice to see you.\")\n",
    "        engine.runAndWait()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        engine.say(\"How are you feeling today?\")\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        # Start speech response in a new thread\n",
    "        speech_thread = threading.Thread(target=process_speech_response)\n",
    "        speech_thread.start()\n",
    "\n",
    "def process_speech_response():\n",
    "    \"\"\"Processes the user's speech response and responds accordingly.\"\"\"\n",
    "    user_response = recognize_speech()\n",
    "    \n",
    "    if user_response:\n",
    "        positive_responses = [\"fine\", \"good\", \"okay\", \"great\", \"happy\", \"excellent\"]\n",
    "        negative_responses = [\"not fine\", \"bad\", \"sad\", \"depressed\", \"terrible\", \"upset\"]\n",
    "        \n",
    "        if any(word in user_response for word in positive_responses):\n",
    "            engine.say(\"That’s wonderful to hear, Sheryar! Stay happy and take care.\")\n",
    "            time.sleep(1)\n",
    "            engine.say(\"Have a great day. Goodbye!\")\n",
    "            engine.runAndWait()\n",
    "        \n",
    "        elif any(word in user_response for word in negative_responses):\n",
    "            engine.say(\"Oh no, I’m really sorry to hear that, Sheryar.\")\n",
    "            time.sleep(1)\n",
    "            engine.say(\"Just remember, you're not alone. I'm always here for you.\")\n",
    "            time.sleep(1)\n",
    "            engine.say(\"Take care of yourself, Sheryar. Goodbye!\")\n",
    "            engine.runAndWait()\n",
    "        \n",
    "        else:\n",
    "            engine.say(\"I'm not sure I understood, but I hope you're doing well, Sheryar.\")\n",
    "            engine.runAndWait()\n",
    "    \n",
    "    # End the program after the interaction\n",
    "    exit()\n",
    "\n",
    "# Capture multiple frames to select the best one\n",
    "best_frame = None\n",
    "max_variance = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        # Calculate sharpness (Laplacian variance)\n",
    "        variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        if variance > max_variance:  # Pick the sharpest frame\n",
    "            max_variance = variance\n",
    "            best_frame = frame.copy()\n",
    "\n",
    "        if len(faces) > 0 and best_frame is not None:\n",
    "            handle_face_detection(best_frame)\n",
    "            break  # Exit loop after detecting and saving the best face\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
